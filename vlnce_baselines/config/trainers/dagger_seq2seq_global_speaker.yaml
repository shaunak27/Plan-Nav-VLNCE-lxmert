BASE_TASK_CONFIG_PATH: habitat_extensions/config/vlnce_global_speaker_task.yaml

USE_CPU: False
SIMULATOR_GPU_ID: 3
TORCH_GPU_ID: 3
NUM_PROCESSES: 1

TENSORBOARD_DIR: data/out/dagger/tensorboard_dirs/seq2seq_global_speaker
CHECKPOINT_FOLDER: data/out/dagger/checkpoints/seq2seq_global_speaker
EVAL_CKPT_PATH_DIR: data/out/dagger/checkpoints/seq2seq_global_speaker
VIDEO_DIR: data/out/dagger/videos/seq2seq_global_speaker
VIDEO_OPTION: ["disk"]
LOG_FILE: "dagger_seq2seq_global_speaker.log"

SENSORS: ["RGB_SENSOR", "DEPTH_SENSOR", "SEMANTIC_SENSOR"]
TRAINER_NAME: "speaker_dagger" 
ENV_NAME:  "VLNCEDaggerEnv" 

EVAL:
  USE_CKPT_CONFIG: False
  SPLIT: val_seen
  EPISODE_COUNT: 100

DAGGER:
  ITERATIONS: 1
  EPOCHS: 15
  # reduce parameter update_size for testing purposes
  UPDATE_SIZE: 10819
  BATCH_SIZE: 5
  P: 1.0
  # TODO: address this
  PRELOAD_LMDB_FEATURES: False
  LMDB_FEATURES_DIR: data/trajectories_dirs/seq2seq/global_speaker_trajectories

MODEL:
  # TODO: address this
  INSTRUCTION_ENCODER:
    use_pretrained_embeddings: True

INFERENCE:
  SPLIT: val_seen
  CKPT_PATH: data/out/dagger/checkpoints/seq2seq_global_speaker/ckpt.14.pth 
  PREDICTIONS_FILE: predictions.json  # where to save your agent's generated trajectories
  USE_CKPT_CONFIG: False
  INFERENCE_NONLEARNING: False
  NONLEARNING:
    AGENT: RandomAgent 

